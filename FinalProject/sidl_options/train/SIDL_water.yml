# ------------------------------------------------------------------------
# Configuration for NAFNet on SIDL-water (validation difficulty: hard)
# ------------------------------------------------------------------------

# Paths for pretrained weights and resume checkpoints
path:
  root: /content/drive/MyDrive/Colab Notebooks/2025_ML/20233011_김연서/NAFNet_experiments
  pretrain_network_g: ~
  strict_load_g: true
  resume_state: ~


name: NAFNet-SIDL-water-width32
model_type: ImageRestorationModel
scale: 1
num_gpu: 1           # Use a single GPU (typical in Colab)
manual_seed: 42

datasets:
  # ----------------------------------------------------------------------
  #                          TRAINING DATASET
  # ----------------------------------------------------------------------
  train:
    name: sidl-water-train
    type: PairedImageDataset
    dataroot_gt: /content/drive/MyDrive/Colab Notebooks/2025_ML/20233011_김연서/train/water/target
    dataroot_lq: /content/drive/MyDrive/Colab Notebooks/2025_ML/20233011_김연서/train/water/input
    io_backend:
      type: disk
    gt_size: 64
    use_flip: true
    use_rot: true
    use_shuffle: true
    num_worker_per_gpu: 2
    batch_size_per_gpu: 8

  # ----------------------------------------------------------------------
  #                          VALIDATION DATASET
  # ----------------------------------------------------------------------
  val:
    name: sidl-water-hard-val
    type: PairedImageDataset
    dataroot_gt: /content/drive/MyDrive/Colab Notebooks/2025_ML/20233011_김연서/val/water/hard/target
    dataroot_lq: /content/drive/MyDrive/Colab Notebooks/2025_ML/20233011_김연서/val/water/hard/input
    io_backend:
      type: disk



# ----------------------------------------------------------------------
#                    NETWORK & TRAINING SETTINGS
# ----------------------------------------------------------------------


# Network architecture settings
network_g:
  type: NAFNetLocal
  width: 16                    # 8 , 32
  enc_blk_nums: [1, 1, 1, 8]  # [1, 1, 1, 1] , [2, 2, 4, 8], [1,1,1,28]
  middle_blk_num: 1           # 2 , 12 ,1
  dec_blk_nums: [1, 1, 1, 1]  # [1, 1, 1, 1] , [2, 2, 2, 2], [1,1,1,1]



# Training hyperparameters
train:
  optim_g:
    type: AdamW
    lr: !!float 1e-3
    weight_decay: !!float 1e-3
    betas: [0.9, 0.9]
  scheduler:
    type: TrueCosineAnnealingLR
    T_max: 200000
    eta_min: !!float 1e-7
  total_iter: 200000
  warmup_iter: -1      # No warm-up
  pixel_opt:
    type: PSNRLoss
    loss_weight: 1
    reduction: mean

# Validation settings
val:
  val_freq: !!float 2000
  save_img: True
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 0
      test_y_channel: false
    ssim:
      type: calculate_ssim
      crop_border: 0
      test_y_channel: false

# Logging configuration (TensorBoard, WandB)
logger:
  print_freq: !!float 10
  save_checkpoint_freq: !!float 2000
  use_tb_logger: true
  wandb:
    project: ~
    resume_id: ~

# Distributed training parameters (not used in single-GPU mode)
dist_params:
  backend: nccl
  port: 29500
